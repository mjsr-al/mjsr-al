{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random as random\nfrom PIL import Image\nimport os\nimport datetime\nimport cv2\nimport glob\nimport json\nfrom types import MethodType\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\nimport six\n\nimport keras\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Softmax, Reshape, Input, Flatten, Conv2DTranspose, Conv2D, GlobalAveragePooling2D,BatchNormalization, Multiply, Dot, Lambda, MaxPooling2D, ReLU, Dropout, Concatenate, ZeroPadding2D, UpSampling2D, Activation\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.models import Model, model_from_json\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.utils import plot_model, to_categorical\nfrom tensorflow.keras.callbacks import ModelCheckpoint, LambdaCallback, ReduceLROnPlateau, CSVLogger, TensorBoard\nfrom tensorflow.keras import backend as K\nimport sklearn\nimport tensorflow_addons as tfa\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-21T19:16:44.581673Z","iopub.execute_input":"2023-06-21T19:16:44.582161Z","iopub.status.idle":"2023-06-21T19:16:52.084006Z","shell.execute_reply.started":"2023-06-21T19:16:44.582067Z","shell.execute_reply":"2023-06-21T19:16:52.082938Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!rm -rf *","metadata":{"execution":{"iopub.status.busy":"2023-06-21T19:16:52.085596Z","iopub.execute_input":"2023-06-21T19:16:52.086283Z","iopub.status.idle":"2023-06-21T19:16:53.193734Z","shell.execute_reply.started":"2023-06-21T19:16:52.086246Z","shell.execute_reply":"2023-06-21T19:16:53.192419Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\ntf.get_logger().setLevel('INFO')\nimport logging\ntf.get_logger().setLevel(logging.ERROR)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T19:16:53.195368Z","iopub.execute_input":"2023-06-21T19:16:53.195763Z","iopub.status.idle":"2023-06-21T19:16:53.202748Z","shell.execute_reply.started":"2023-06-21T19:16:53.195724Z","shell.execute_reply":"2023-06-21T19:16:53.201583Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from tensorflow.python.framework import ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.keras import backend as K\nimport tensorflow.keras as keras","metadata":{"execution":{"iopub.status.busy":"2023-06-21T19:16:53.204791Z","iopub.execute_input":"2023-06-21T19:16:53.205116Z","iopub.status.idle":"2023-06-21T19:16:53.217213Z","shell.execute_reply.started":"2023-06-21T19:16:53.205085Z","shell.execute_reply":"2023-06-21T19:16:53.216255Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# class 1 -- ['l_lip','u_lip','mouth','neck','nose','neck_l']\n# class 2 -- ['l_brow', 'r_brow', 'l_eye', 'r_eye']\n\nhyperparameters={\n    'targets': ['image_id'],\n    'classes': ['l_lip','u_lip','mouth','neck','nose','neck_l'],\n    'height': 256, \n    'width': 256 ,\n    'channels': 3, \n    'batch_size': 8, \n    'epochs': 1, \n    'num_tasks': 6, ### MODIFY\n    'initializer': 'he_uniform', \n    'reg_lambda': 1e-5, \n    'output': [2]*6, ### MODIFY === [2]*number of tasks\n    'attrPerTask': 2,\n    'lr': 1e-5, ### MODIFY\n    'is_trained': False, \n    'dropout_prob': 0.3,\n    'enable_cs': False, \n    'enable_sluice': False,\n    'initial_percent':0.3,\n    'initial_train_epoch':3, ### NEED TO SEE----- Done\n    'increment_train_epoch':3, ### NEED TO SEE --- Done\n    'uncertainity_repeat': 5, \n    'num_uncertain_elements': 1208, \n    'additional_epoch': 5, ### NEED TO SEE\n    'pretraining_epochs': 4, ### -- make it 2 or originally 1 - Done\n    'train_initial_batches': 2418, #6103, ### NEED TO SEE ------------- Done\n    'enable_additional': False,\n    'additional_attr_count':2,\n    'all_updates':False,\n    'initial_percent_val': 0.6, ### Added Now\n    'split_index': 4 ### Added Now\n    }","metadata":{"execution":{"iopub.status.busy":"2023-06-21T19:16:53.218496Z","iopub.execute_input":"2023-06-21T19:16:53.218828Z","iopub.status.idle":"2023-06-21T19:16:53.230129Z","shell.execute_reply.started":"2023-06-21T19:16:53.218797Z","shell.execute_reply":"2023-06-21T19:16:53.229254Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# hyperparameters={\n#     'num_tasks': 7, ### MODIFY\n#     'output': [2]*7, ### MODIFY === [2]*number of tasks\n#     'lr': 5e-4, ### MODIFY\n#     'num_uncertain_elements': 148, \n#     'pretraining_epochs': 4, ### -- make it 2 or originally 1 - Done\n#     'train_initial_batches': 74, #6103, ### NEED TO SEE ------------- Done\n#     'initial_percent_val': 0.6, ### Added Now\n#     }","metadata":{"execution":{"iopub.status.busy":"2023-06-21T19:16:53.231576Z","iopub.execute_input":"2023-06-21T19:16:53.232226Z","iopub.status.idle":"2023-06-21T19:16:53.248715Z","shell.execute_reply.started":"2023-06-21T19:16:53.232163Z","shell.execute_reply":"2023-06-21T19:16:53.247942Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def preprocess(hyperparameters, eval_partition, celeba_to_mask):\n\n    celeba_to_mask = celeba_to_mask.rename({'orig_file':'image_id'},axis='columns')\n    celeba_to_mask = celeba_to_mask.set_index('image_id')\n    eval_partition = eval_partition.set_index('image_id')\n    \n    k = celeba_to_mask.join(eval_partition)\n    k = k.reset_index()\n    k['idx'] = k['idx'].astype(str)+'.jpg'\n    k = k.drop(['image_id', 'orig_idx'], axis=1)\n\n    train = k.loc[k['partition']==0]\n    val = k.loc[k['partition']==1]\n    test = k.loc[k['partition']==2]\n    \n    train = train.drop('partition', axis=1)\n    val = val.drop('partition', axis=1)\n    test = test.drop('partition', axis=1)\n    \n    train = train[:(len(train)//hyperparameters['batch_size'])*hyperparameters['batch_size']]\n    val = val[:(len(val)//hyperparameters['batch_size'])*hyperparameters['batch_size']]\n    test = test[:(len(test)//hyperparameters['batch_size'])*hyperparameters['batch_size']]\n    \n    return (train, val, test)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T19:16:53.250236Z","iopub.execute_input":"2023-06-21T19:16:53.250935Z","iopub.status.idle":"2023-06-21T19:16:53.264190Z","shell.execute_reply.started":"2023-06-21T19:16:53.250888Z","shell.execute_reply":"2023-06-21T19:16:53.263227Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"attr = pd.read_csv('/kaggle/input/celebamaskhq/CelebAMask-HQ/CelebAMask-HQ-attribute-anno.txt', skiprows=1, sep=\" \")\nceleba_to_mask = pd.read_csv('/kaggle/input/celebamaskhq/CelebAMask-HQ/CelebA-HQ-to-CelebA-mapping.txt', header=0, delim_whitespace=True)\neval_partition = pd.read_csv('/kaggle/input/celeba-dataset/list_eval_partition.csv')\n\n(train, val, test) = preprocess(hyperparameters, eval_partition, celeba_to_mask)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T19:16:53.265464Z","iopub.execute_input":"2023-06-21T19:16:53.265838Z","iopub.status.idle":"2023-06-21T19:16:53.952370Z","shell.execute_reply.started":"2023-06-21T19:16:53.265804Z","shell.execute_reply":"2023-06-21T19:16:53.951485Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Parameters\nparams = {'dim': (hyperparameters['height'],hyperparameters['width']),\n          'batch_size': hyperparameters['batch_size'],\n          'n_channels': hyperparameters['channels'],\n          'shuffle': True}\n\n# Datasets\npartition = {}\npartition['train'] = train.idx.values\npartition['val'] =  val.idx.values\npartition['test'] =  test.idx.values\n\nfolder_base = '../input/celebamaskhq/CelebAMask-HQ/CelebAMask-HQ-mask-anno'\nlabels = {}\n\nprint('Done')\nfor i in partition['train']:\n    labels[i] = []\n\n    for label in hyperparameters['classes']:\n        filename = os.path.join(folder_base, str(int(i.split(\".\")[0])//2000), str(i.split(\".\")[0]).rjust(5, '0') + '_' + label + '.png')\n        if (os.path.exists(filename)):\n            labels[i].append(filename)\n        else:\n            labels[i].append('empty')\n\nprint('Done')\nfor i in partition['val']:\n    labels[i] = []\n\n    for label in hyperparameters['classes']:\n        filename = os.path.join(folder_base, str(int(i.split(\".\")[0])//2000), str(i.split(\".\")[0]).rjust(5, '0') + '_' + label + '.png')\n        if (os.path.exists(filename)):\n            labels[i].append(filename)\n        else:\n            labels[i].append('empty')\n            \nprint('Done')\nfor i in partition['test']:\n    labels[i] = []\n\n    for label in hyperparameters['classes']:\n        filename = os.path.join(folder_base, str(int(i.split(\".\")[0])//2000), str(i.split(\".\")[0]).rjust(5, '0') + '_' + label + '.png')\n        if (os.path.exists(filename)):\n            labels[i].append(filename)\n        else:\n            labels[i].append('empty')","metadata":{"execution":{"iopub.status.busy":"2023-06-21T19:16:56.519237Z","iopub.execute_input":"2023-06-21T19:16:56.519818Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Done\n","output_type":"stream"}]},{"cell_type":"code","source":"# import pickle\n# a_file = open(\"labels_classes_1.pkl\", \"wb\")\n# pickle.dump(labels, a_file)\n# a_file.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# len(partition['train']), len(partition['val']), len(partition['test']), \n\n# arr1=[0,0,0,0,0,0]\n# for i in range(len(classes)):\n#     for j in partition['train']:\n#         if classes[i] not in p[j]:\n#             arr1[i]+=1\n# arr2=[0,0,0,0,0,0]\n# for i in range(len(classes)):\n#     for j in partition['val']:\n#         if classes[i] not in p[j]:\n#             arr2[i]+=1\n# arr3=[0,0,0,0,0,0]\n# for i in range(len(classes)):\n#     for j in partition['test']:\n#         if classes[i] not in p[j]:\n#             arr3[i]+=1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# file = '0.jpg'\n# j = '../input/celebamaskhq/CelebAMask-HQ/CelebAMask-HQ-mask-anno/0/00000_l_lip.png'\n# i = '../input/celebamaskhq/CelebAMask-HQ/CelebA-HQ-img/' + file\n# img = plt.imread(j)\n# plt.imshow(img)\n# print(img.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# folder_base = '../input/celebamaskhq/CelebAMask-HQ/CelebAMask-HQ-mask-anno'\n\n# for label in classes:\n#     filename = os.path.join(folder_base, file.split(\".\")[0], str(file.split(\".\")[0]).rjust(5, '0') + '_' + label + '.png')\n#     if (os.path.exists(filename)):\n#         print(label)\n#         lab = cv2.imread(filename)\n#         print(lab.shape)\n#         plt.figure()\n#         plt.imshow(lab)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def augment_using_layers(images, masks, size=None, val=False):\n    \n    h_s = size[0]\n    w_s = size[1]\n    \n    def aug(height=h_s, width=w_s, validation=val):\n        \n        resize = tf.keras.layers.Resizing(height, width, interpolation='nearest')\n        \n        flip = tf.keras.layers.RandomFlip(mode=\"horizontal\")\n        \n        rota = tf.keras.layers.RandomRotation(0.1, fill_mode='wrap', interpolation='nearest')\n        \n        trans = tf.keras.layers.RandomTranslation(height_factor=(-0.1, 0.1),\n                                            width_factor=(-0.1, 0.1), \n                                            fill_mode='wrap',interpolation='nearest')\n                \n        if validation:\n            layers = [resize] \n        else:\n            layers = [resize, flip, rota]\n        aug_model = tf.keras.Sequential(layers)\n\n        return aug_model\n    \n    aug = aug()\n    \n    if masks is not None:\n        mask = tf.stack(masks, -1)\n        mask = tf.cast(mask, 'float32')\n        images_mask = tf.concat([images, mask], -1)          \n    else:\n        images_mask = tf.cast(images, 'float32')\n    \n    images_mask = aug(images_mask)  \n    images_mask=images_mask.numpy()\n    images_mask=images_mask.astype(np.float64)\n\n    if masks is not None:\n        image = images_mask[:,:,0:3] / 255.0\n        labels=[]\n        for i in range(hyperparameters['num_tasks']):\n            labels.append(images_mask[:, :, 3+i] / 255.0)\n        return image, labels\n    else:\n        image = images_mask[:,:,0:3] / 255.0\n        mask = None\n        return image, None","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n\n    def __init__(self, list_IDs, labels, classes, batch_size=32, dim=(512,512), n_channels=3,shuffle=True, is_validation=False):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.labels = labels\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.shuffle = shuffle\n        self.classes = classes\n        self.is_validation = is_validation\n        self.on_epoch_end()\n\n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n            \n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        y1 = np.empty((self.batch_size, *self.dim), dtype=int)\n        y2 = np.empty((self.batch_size, *self.dim), dtype=int)\n        y3 = np.empty((self.batch_size, *self.dim), dtype=int)\n        y4 = np.empty((self.batch_size, *self.dim), dtype=int)\n        y5 = np.empty((self.batch_size, *self.dim), dtype=int)\n        y6 = np.empty((self.batch_size, *self.dim), dtype=int)\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_temp):\n            # Store sample\n            if type(ID) == list or type(ID) == np.ndarray:\n                k = ID[0]\n            else:\n                k = ID\n                \n            img = cv2.imread('../input/celebamaskhq/CelebAMask-HQ/CelebA-HQ-img/' + k)\n            img = cv2.resize(img, (512,512), interpolation = cv2.INTER_NEAREST)\n            \n            labs = []\n            for x in range(len(self.classes)):\n                labs.append(0)\n                \n            for j in range(len(self.classes)):\n                if self.labels[k][j] != 'empty':\n                    labs[j] = cv2.imread(self.labels[k][j])[:,:,0]\n                else:\n                    labs[j] = np.zeros((512,512), dtype=np.uint8)\n                    \n            # aug. dataset\n            img_1, labs_1 = augment_using_layers(img, labs, (hyperparameters['height'], hyperparameters['width']), self.is_validation)\n            \n            X[i,] = img_1\n            y1[i, ] = labs_1[0]\n            y2[i, ] = labs_1[1]\n            y3[i, ] = labs_1[2]\n            y4[i, ] = labs_1[3]\n            y5[i, ] = labs_1[4]\n            y6[i, ] = labs_1[5]\n        \n        return X, [y1, y2, y3, y4, y5, y6]\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n\n        return X, y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MultipleGenerator(keras.utils.Sequence):\n    \n    def __init__(self, list_IDs_1, list_IDs_2, labels, classes, batch_size=32, dim=(512,512), n_channels=3,shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.labels = labels\n        self.list_IDs_1 = list_IDs_1\n        self.list_IDs_2 = list_IDs_2\n        self.n_channels = n_channels\n        self.shuffle = shuffle\n        self.classes = classes\n        self.on_epoch_end()\n        \n    def on_epoch_end(self):\n        self.indexes_1 = np.arange(len(self.list_IDs_1))\n        self.indexes_2 = np.arange(len(self.list_IDs_2))\n\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes_1)\n            np.random.shuffle(self.indexes_2)\n    \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs_1) / self.batch_size))\n\n    def __data_generation(self, list_IDs_temp_1, list_IDs_temp_2):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X1 = np.empty((self.batch_size, *self.dim, self.n_channels))\n        X2 = np.empty((self.batch_size, *self.dim, self.n_channels))\n        y1 = np.empty((self.batch_size, *self.dim), dtype=int)\n        y2 = np.empty((self.batch_size, *self.dim), dtype=int)\n        y3 = np.empty((self.batch_size, *self.dim), dtype=int)\n        y4 = np.empty((self.batch_size, *self.dim), dtype=int)\n        y5 = np.empty((self.batch_size, *self.dim), dtype=int)\n        y6 = np.empty((self.batch_size, *self.dim), dtype=int)\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_temp_1):\n            # Store sample\n            img = cv2.imread('../input/celebamaskhq/CelebAMask-HQ/CelebA-HQ-img/' + ID[0])\n            img = cv2.resize(img, (512,512), interpolation = cv2.INTER_NEAREST)\n            \n            labs = []\n            for x in range(len(self.classes)):\n                labs.append(0)\n            \n            for j in range(len(self.classes)):\n                if self.labels[ID[0]][j] != 'empty':\n                    labs[j] = cv2.imread(self.labels[ID[0]][j])[:,:,0]\n                else:\n                    labs[j] = np.zeros((512,512), dtype=np.uint8)\n            \n            # aug. dataset\n            img_1, labs_1 = augment_using_layers(img, labs, (hyperparameters['height'], hyperparameters['width']))\n            \n            X1[i,] = img_1\n            y1[i, ] = labs_1[0]\n            y2[i, ] = labs_1[1]\n            y3[i, ] = labs_1[2]\n            y4[i, ] = labs_1[3]\n            y5[i, ] = labs_1[4]\n            y6[i, ] = labs_1[5]\n        \n        for i, ID in enumerate(list_IDs_temp_2):\n            # Store sample\n\n            img = cv2.imread('../input/celebamaskhq/CelebAMask-HQ/CelebA-HQ-img/' + ID[0])\n            img = cv2.resize(img, (512,512), interpolation = cv2.INTER_NEAREST)\n\n            img_1, labs_1 = augment_using_layers(img, None, (hyperparameters['height'], hyperparameters['width']))                        \n            \n            X2[i,] = img_1\n\n        return X1, X2, [y1, y2, y3, y4, y5, y6]\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes_1 = self.indexes_1[index*self.batch_size:(index+1)*self.batch_size]\n        indexes_2 = self.indexes_2[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp_1 = [self.list_IDs_1[k] for k in indexes_1]\n        list_IDs_temp_2 = [self.list_IDs_2[k] for k in indexes_2]\n\n        # Generate data\n        X1, X2, Y = self.__data_generation(list_IDs_temp_1, list_IDs_temp_2)\n\n        return X1, X2, Y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gen_full = DataGenerator(partition['train'], \n                                   labels, hyperparameters['classes'],\n                                   dim = (hyperparameters['height'],hyperparameters['width']),\n                                   batch_size= hyperparameters['batch_size'],\n                                   n_channels = hyperparameters['channels'],\n                                   shuffle = True, \n                                   is_validation=False)\n\nval_gen = DataGenerator(partition['val'], \n                                   labels, hyperparameters['classes'],\n                                   dim = (hyperparameters['height'],hyperparameters['width']),\n                                   batch_size= hyperparameters['batch_size'],\n                                   n_channels =hyperparameters['channels'],\n                                   shuffle = False, \n                                   is_validation=True)\n\ntest_gen = DataGenerator(partition['test'], \n                                   labels, hyperparameters['classes'],\n                                   dim = (hyperparameters['height'],hyperparameters['width']),\n                                   batch_size= hyperparameters['batch_size'],\n                                   n_channels =hyperparameters['channels'],\n                                   shuffle = False, \n                                   is_validation=True)\n\n# pretrain_gen = MultipleGenerator(labelled_pretrain.values, \n#                                       unlabelled_pretrain.values, \n#                                       labels, hyperparameters['classes'],\n#                                       batch_size= hyperparameters['batch_size'],\n#                                       dim = (hyperparameters['height'],hyperparameters['width']),\n#                                       n_channels = hyperparameters['channels'],\n#                                       shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Architecture","metadata":{}},{"cell_type":"code","source":"def discriminator():\n    \n    X = Input((360,), name='input_disc')\n    \n    x = Dense(units = 512, activation = None, name='dense_1_disc')(X)\n    x = BatchNormalization(name = 'bn_1_disc')(x)\n    x = ReLU(name='relu_1_disc')(x)\n    x = Dense(units = 512, activation = None, name='dense_2_disc')(x)\n    x = BatchNormalization(name = 'bn_2_disc')(x)\n    x = ReLU(name='relu_2_disc')(x)\n    x = Dense(units = 1, activation = 'sigmoid', name='output_disc')(x)\n    \n    return X,x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def variationalAutoEncoder(embed_size=360):\n    \n    img_input = Input(shape=(hyperparameters['height'],hyperparameters['width'],hyperparameters['channels']), name = 'input_vae')\n\n    x = Conv2D(64, (3, 3), activation='relu', padding='same',\n               name='conv_1_vae')(img_input)\n    x = Conv2D(64, (3, 3), activation='relu', padding='same',\n               name='conv_2_vae')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='pooling_1_vae')(x)\n    \n    # Block 2\n    x = Conv2D(128, (3, 3), activation='relu', padding='same',\n               name='conv_3_vae')(x)\n    x = Conv2D(128, (3, 3), activation='relu', padding='same',\n               name='conv_4_vae')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='pooling_2_vae')(x)\n\n    # Block 3\n    x = Conv2D(256, (3, 3), activation='relu', padding='same',\n               name='conv_5_vae')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same',\n               name='conv_6_vae')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same',\n               name='conv_7_vae')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='pooling_3_vae')(x)\n\n    # Block 4\n    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n               name='conv_8_vae')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n               name='conv_9_vae')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n               name='conv_10_vae')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='pooling_4_vae')(x)\n\n    # Block 5\n    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n               name='conv_11_vae')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n               name='conv_12_vae')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n               name='conv_13_vae')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='pooling_5_vae')(x)\n    f5 = x\n    \n    x = Conv2D(32, (1, 1), activation='relu', padding='same',\n               name='conv_14_vae')(x)    \n    \n    x = Flatten(name='flatten_1_vae')(x)\n    mu = Dense(units = embed_size, activation = None, name='dense_1_vae')(x)\n    \n    x = Dense(units = 8192, activation = None, name='dense_2_vae')(mu)\n    x = Reshape((16,16,32), name='reshape_vae')(x)\n    x = Conv2DTranspose(512, kernel_size=(1,1), padding='same', use_bias=False, name='conv_15_vae')(x)\n    \n    x = (ZeroPadding2D((1, 1), name='zero_padding_1_vae'))(x)\n    x = (Conv2D(512, (3, 3), padding='valid', name='conv_16_vae'))(x)\n    x = (BatchNormalization(name = 'bn_1_vae'))(x)\n    x = tf.keras.layers.ReLU(name='relu_vae_1')(x)\n\n    x = (UpSampling2D((2, 2), name='upsampling_1_vae'))(x)\n    x = (ZeroPadding2D((1, 1), name='zero_padding_2_vae'))(x)\n    x = (Conv2D(256, (3, 3), padding='valid' ,name='conv_17_vae'))(x)\n    x = (BatchNormalization(name = 'bn_2_vae'))(x)\n    x = tf.keras.layers.ReLU(name='relu_vae_2')(x)\n\n    x = (UpSampling2D((2, 2),  name='upsampling_2_vae'))(x)\n    x = (ZeroPadding2D((1, 1),  name='zero_padding_3_vae'))(x)\n    x = (Conv2D(128, (3, 3), padding='valid', name='conv_18_vae'))(x)\n    x = (BatchNormalization(name = 'bn_3_vae'))(x)\n    x = tf.keras.layers.ReLU(name='relu_vae_3')(x)\n\n    x = (UpSampling2D((2, 2),  name='upsampling_3_vae'))(x)\n    x = (ZeroPadding2D((1, 1),  name='zero_padding_4_vae'))(x)\n    x = (Conv2D(128, (3, 3), padding='valid', name='conv_19_vae'))(x)\n    x = (BatchNormalization(name = 'bn_4_vae'))(x)\n    x = tf.keras.layers.ReLU(name='relu_vae_4')(x)\n\n    x = (UpSampling2D((2, 2),  name='upsampling_4_vae'))(x)\n    x = (ZeroPadding2D((1, 1),  name='zero_padding_5_vae'))(x)\n    x = (Conv2D(64, (3, 3), padding='valid', name='conv_20_vae'))(x)\n    x = (BatchNormalization(name = 'bn_5_vae'))(x)\n    x = tf.keras.layers.ReLU(name='relu_vae_5')(x)\n\n    # x = (UpSampling2D((2, 2),  name='upsampling_5_vae'))(x)\n    x = (ZeroPadding2D((1, 1),  name='zero_padding_6_vae'))(x)\n    x = (Conv2D(3, (3, 3), padding='valid', name='conv_21_vae'))(x)\n    x = (BatchNormalization(name = 'bn_6_vae'))(x)\n    x = tf.keras.layers.ReLU(name='relu_vae_6')(x)\n\n    return img_input, x, mu","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predictor - SegNet","metadata":{}},{"cell_type":"code","source":"def get_vgg_encoder(input_height=224, input_width=224, pretrained='imagenet', channels=3):\n\n    assert input_height % 32 == 0\n    assert input_width % 32 == 0\n\n    img_input = Input(shape=(input_height, input_width, channels), name = 'input_pred')\n\n    x = Conv2D(64, (3, 3), activation='relu', padding='same',\n               name='block1_conv1')(img_input)\n    x = Conv2D(64, (3, 3), activation='relu', padding='same',\n               name='block1_conv2')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n    \n    f1 = x\n    # Block 2\n    x = Conv2D(128, (3, 3), activation='relu', padding='same',\n               name='block2_conv1')(x)\n    x = Conv2D(128, (3, 3), activation='relu', padding='same',\n               name='block2_conv2')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n    f2 = x\n\n    # Block 3\n    x = Conv2D(256, (3, 3), activation='relu', padding='same',\n               name='block3_conv1')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same',\n               name='block3_conv2')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same',\n               name='block3_conv3')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n    f3 = x\n\n    # Block 4\n    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n               name='block4_conv1')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n               name='block4_conv2')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n               name='block4_conv3')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n    f4 = x\n\n    # Block 5\n    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n               name='block5_conv1')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n               name='block5_conv2')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n               name='block5_conv3')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n    f5 = x\n\n    return img_input, [f1, f2, f3, f4, f5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def segnet_decoder(f, n_classes, n_up=3):\n\n    assert n_up >= 2\n    \n    ## added ---------------------------------------------------------------\n#     f = Conv2D(8, (1, 1), padding='valid', name='conv_1_pred')(f) \n#     f = Flatten(name='flatten_1_pred')(f)\n    f = Conv2D(360, (1, 1), padding='valid', name='conv_1_pred')(f) \n    f = GlobalAveragePooling2D(name = \"gap_1_pred\")(f)\n    \n    f = Dense(units = 360, activation = None, name='dense_1_pred')(f)  \n    g = f\n    f = Dense(units = 64*64*8, activation = 'relu', name='dense_2_pred')(f)  \n    f = Reshape((64,64,8), name='reshape_1_pred')(f)\n    f = (Conv2D(256, (1, 1), padding='valid', name='conv_2_pred'))(f)\n    ## --------------------------------------------------------------------\n\n    o = f\n    o = (ZeroPadding2D((1, 1), name = 'zero_1_pred'))(o)\n    o = (Conv2D(512, (3, 3), padding='valid', name='conv_3_pred'))(o)\n    o = (BatchNormalization(name = 'bn_1_pred'))(o)\n    \n    o = tf.keras.layers.SpatialDropout2D(0.3)(o)\n\n    o = (UpSampling2D((2, 2), name = 'upsampling_1_pred'))(o)\n    o = (ZeroPadding2D((1, 1), name = 'zero_2_pred'))(o)\n    o = (Conv2D(256, (3, 3), padding='valid', name='conv_4_pred'))(o)\n    o = (BatchNormalization(name = 'bn_2_pred'))(o)\n    \n    o = (UpSampling2D((2, 2), name = 'upsampling_2_pred'))(o)\n    o = (ZeroPadding2D((1, 1), name = 'zero_3_pred'))(o)\n    o = (Conv2D(128, (3, 3), padding='valid', name = 'conv_5_pred'))(o)\n    o = (BatchNormalization(name = 'bn_3_pred'))(o)\n\n#     o = (UpSampling2D((2, 2), name = 'upsampling_3_pred'))(o)\n#     o = (ZeroPadding2D((1, 1), name = 'zero_4_pred'))(o)\n#     o = (Conv2D(64, (3, 3), padding='valid', name = 'conv_6_pred'))(o)\n#     o = (BatchNormalization(name = 'bn_4_pred'))(o)\n\n#     o = Conv2D(n_classes, (3, 3), padding='same', name = 'conv_7_pred')(o)\n\n    t1 = []\n    for i in range(hyperparameters['num_tasks']):\n        t1.append(Conv2D(1, (3, 3), padding='same', name = 'conv_7_'+ str(i) +'_pred', activation='sigmoid')(o))\n\n    return t1, g","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_segmentation_model(input, output):\n\n    img_input = input\n    o1,o2 = output\n\n#     o_shape = Model(img_input, [o1,o2]).output_shape\n#     i_shape = Model(img_input, [o1,o2]).input_shape\n    \n#     IMAGE_ORDERING = 'channels_last'\n#     output_height = o_shape[0][1]\n#     output_width = o_shape[0][2]\n#     input_height = i_shape[1]\n#     input_width = i_shape[2]\n#     n_classes = o_shape[0][3]\n    \n    # o1 = (Reshape((output_height*output_width, -1), name='reshape_2_pred'))(o1)\n\n    # o1 = (Activation('softmax', name='activation_1_pred'))(o1)\n    model = Model(img_input, [o1, o2])\n    \n    # model.output_width = output_width\n    # model.output_height = output_height\n    \n#     model.n_classes = n_classes\n#     model.input_height = input_height\n#     model.input_width = input_width\n#     model.model_name = \"\"\n\n    return model\n\ndef vgg_segnet(n_classes, input_height=416, input_width=608, encoder_level=3, channels=3):\n\n    model = _segnet(n_classes, get_vgg_encoder,  input_height=input_height,\n                    input_width=input_width, encoder_level=encoder_level, channels=channels)\n    model.model_name = \"vgg_segnet\"\n    return model\n\ndef _segnet(n_classes, encoder,  input_height=512, input_width=512,\n            encoder_level=3, channels=3):\n\n    img_input, levels = encoder(\n        input_height=input_height,  input_width=input_width, channels=channels)\n\n    feat = levels[encoder_level]\n    o = segnet_decoder(feat, n_classes, n_up=3)\n    model = get_segmentation_model(img_input, o)\n\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pred_model = vgg_segnet(n_classes = hyperparameters['num_tasks'], input_height=hyperparameters['height'], input_width=hyperparameters['width'], encoder_level=2, channels=hyperparameters['channels'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ActiveLearning(keras.Model):\n    def __init__(self, discriminator, generator, predictor, hyperparameters, trackers):\n        super(ActiveLearning, self).__init__()\n        self.discriminator = discriminator\n        self.generator = generator\n        self.predictor = predictor\n        self.hyperparameters = hyperparameters\n        self.trackers = trackers\n\n    def compile(self, d_optimizer, g_optimizer, p_optimizer):\n        super(ActiveLearning, self).compile()\n        self.d_optimizer = d_optimizer\n        self.g_optimizer = g_optimizer\n        self.p_optimizer = p_optimizer\n                \n    def train_step(self, real_images):\n        \n        # get labelled_x, unlabelled_x and labelled_y\n        \n        x = real_images\n        labelled_x = x[0]\n        unlabelled_x = x[1]\n        labelled_y = x[2]\n\n        ##### TRAIN THE PREDICTOR #####\n        \n        # Compute output and latents\n        with tf.GradientTape() as tape:\n            labelled_prediction_y,_ = self.predictor(labelled_x, training=True)\n\n            re_1=[]\n            for i in range(hyperparameters['num_tasks']):\n                re_1.append(tf.reshape(labelled_y[i], (hyperparameters['batch_size'], -1)))\n\n            re_2 = []\n            for i in range(hyperparameters['num_tasks']):\n                re_2.append(tf.reshape(labelled_prediction_y[i], (hyperparameters['batch_size'], -1)))\n\n#             weights = [{0: 1, 1: 1},\n#              {0: 1, 1: 1},\n#              {0: 1, 1: 1},\n#              {0: 1, 1: 1},\n#              {0: 1, 1: 1},\n#              {0: 1, 1: 1}]\n\n            weights = [{0: 0.5034, 1: 73.4329}, {0: 0.5021, 1:  116.4345}, \n                       {0: 0.5017, 1: 145.4393}, {0: 0.5218, 1: 11.9351}, \n                       {0: 0.5105, 1: 24.1370}, {0: 0.5002, 1: 1276.3078}]\n\n            w = []\n            for i in range(hyperparameters['num_tasks']):\n                wts = np.zeros((re_1[i].shape))\n                for j in range(re_1[i].shape[0]):\n                    t = re_1[i][j].numpy()\n                    t = t.astype('float64')\n                    wts[j][t==0] = weights[i][0]\n                    wts[j][t==1] = weights[i][1]\n\n                wts=tf.convert_to_tensor(wts)\n                predictor_loss = weighted_cross_entropy(re_1[i], re_2[i], sample_weights=wts)\n                w.append(predictor_loss)\n            w = tf.convert_to_tensor(w)\n            w = tf.math.reduce_mean(w, axis=1) +  tf.cast(dice_coef_loss(re_1, re_2, self.hyperparameters['num_tasks']), tf.float32)\n\n        trainable_vars = self.predictor.trainable_variables\n        gradients = tape.gradient(w, trainable_vars)\n\n        # Update weights\n        self.p_optimizer.apply_gradients(zip(gradients, trainable_vars))  \n                \n        # ------------------------------------------------------------------------------------------------\n        \n        ##### TRAIN THE GENERATOR #####\n        \n        # Create labels for VAE\n        labelled_disc_true = np.ones((hyperparameters['batch_size'],1))\n        unlabelled_disc_fake = np.ones((hyperparameters['batch_size'],1))\n        \n        # Compute VAE outputs\n        with tf.GradientTape() as tape:\n            # Compute generator o/p\n            labelled_vae_y, labelled_vae_latent = self.generator(labelled_x)\n            unlabelled_vae_y, unlabelled_vae_latent = self.generator(unlabelled_x)\n            \n            # Calculate loss for VAE\n            labelled_vae_loss = keras.losses.mean_squared_error(labelled_x, labelled_vae_y) # ----> 2\n            unlabelled_vae_loss = keras.losses.mean_squared_error(unlabelled_x, unlabelled_vae_y) # ----> 2\n            \n            vae_loss = labelled_vae_loss + unlabelled_vae_loss #+ (self.advisory_param*disc_loss)\n        \n        # Compute gradients\n        trainable_vars = self.generator.trainable_variables\n        gradients = tape.gradient(vae_loss, trainable_vars)\n        \n        # Update weights\n        self.g_optimizer.apply_gradients(zip(gradients, trainable_vars))         \n        \n        # ------------------------------------------------------------------------------------------------\n        \n        ##### TRAIN THE DISCRIMINATOR #####\n        \n        # Create disc labels\n        labelled_disc_true = np.ones((hyperparameters['batch_size'],1))\n        unlabelled_disc_true = np.zeros((hyperparameters['batch_size'],1))\n        \n        # Compute VAE latents\n        _, labelled_vae_latent = self.generator(labelled_x, training = False)\n        _, unlabelled_vae_latent = self.generator(unlabelled_x, training = False)\n        \n        # Compute predictor latents\n        _, labelled_predictor_latent = self.predictor(labelled_x, training=False)\n        _, unlabelled_predictor_latent = self.predictor(unlabelled_x, training=False)\n        \n#         labelled_predictor_latent = math_ops.mean(ops.convert_to_tensor(labelled_predictor_latent), axis=0)\n#         unlabelled_predictor_latent = math_ops.mean(ops.convert_to_tensor(unlabelled_predictor_latent), axis=0)\n        \n        # Join vae and predictor latents\n        labelled_disc_in = labelled_vae_latent # tf.concat([labelled_vae_latent,labelled_predictor_latent],axis=1)\n        unlabelled_disc_in = unlabelled_vae_latent # tf.concat([unlabelled_vae_latent,unlabelled_predictor_latent],axis=1)\n        \n        # Compute disc output\n        with tf.GradientTape() as tape:\n            labelled_disc_y = self.discriminator(labelled_disc_in,training=True)\n            unlabelled_disc_y = self.discriminator(unlabelled_disc_in,training=True)\n            \n            labelled_disc_loss = keras.losses.binary_crossentropy(labelled_disc_true, labelled_disc_y) # ----> 3\n            unlabelled_dic_loss = keras.losses.binary_crossentropy(unlabelled_disc_true, unlabelled_disc_y) # ----> 3\n            \n            disc_loss = labelled_disc_loss + unlabelled_dic_loss\n        \n        # Compute gradients\n        trainable_vars = self.discriminator.trainable_variables\n        gradients = tape.gradient(disc_loss, trainable_vars)\n        \n        # Update weights\n        self.d_optimizer.apply_gradients(zip(gradients, trainable_vars)) \n    \n        # ------------------------------------------------------------------------------------------------\n        \n        # Computing Metrics\n        \n        # For predictor\n        \n        self.trackers['loss_tracker_predictor'].update_state(w) # predictor_loss\n        self.trackers['acc_metric_predictor'].update_state(re_1, re_2)\n\n        for task in range(self.hyperparameters['num_tasks']):\n            acc=tf.keras.metrics.BinaryAccuracy()\n            accuracy = acc(re_1[task], re_2[task])\n            self.trackers['individual_acc_predictor'][task].update_state(accuracy)\n            self.trackers['individual_IOU_predictor'][task].update_state(re_1[task], tf.cast(re_2[task]>=0.5, tf.int64))\n\n        # For VAE\n        self.trackers['loss_tracker_generator'].update_state(labelled_x, labelled_vae_y)\n        self.trackers['loss_tracker_generator'].update_state(unlabelled_x, unlabelled_vae_y)\n        \n        # For Discriminator\n        self.trackers['loss_tracker_disc'].update_state(labelled_disc_true,labelled_disc_y)\n        self.trackers['loss_tracker_disc'].update_state(unlabelled_disc_true,unlabelled_disc_y)\n        self.trackers['acc_tracker_disc'].update_state(labelled_disc_true,labelled_disc_y)\n        self.trackers['acc_tracker_disc'].update_state(unlabelled_disc_true,unlabelled_disc_y)\n            \n        ret_dic = {\"loss_predictor_total\": self.trackers['loss_tracker_predictor'].result(), # loss_tracker_predictor.result(), \n                   \"acc_predictor\":self.trackers['acc_metric_predictor'].result(), # acc_metric_predictor.result(), \n                   \"loss_VAE\":  self.trackers['loss_tracker_generator'].result(), # loss_tracker_generator.result(),\n                   \"loss_disc\": self.trackers['loss_tracker_disc'].result(), # loss_tracker_disc.result(),\n                   \"acc_disc\": self.trackers['acc_tracker_disc'].result(), # acc_tracker_disc.result()\n                  }\n        \n        for i in range(hyperparameters['num_tasks']):\n            ret_dic[\"acc_predictor_\"+str(i)] = self.trackers['individual_acc_predictor'][i].result() # individual_acc_metric_predictor[i].result()\n            ret_dic[\"IOU_predictor_\"+str(i)] = self.trackers['individual_IOU_predictor'][i].result() # individual_acc_metric_predictor[i].result()\n\n        return ret_dic\n    \n    def call(self, x):\n        return    \n    \n    def test_step(self, real_images):\n        \n        x = real_images\n        labelled_x = x[0]\n        labelled_y = x[1]\n        \n        # Predictor step\n        labelled_prediction_y, labelled_predictor_latent = self.predictor(labelled_x, training=False)\n        \n        # Generator step\n        labelled_vae_y, labelled_vae_latent = self.generator(labelled_x, training=False)\n        \n        # Discriminator step\n#         labelled_predictor_latent = math_ops.mean(ops.convert_to_tensor(labelled_predictor_latent), axis=0)\n        labelled_disc_in = labelled_vae_latent #tf.concat([labelled_vae_latent,labelled_predictor_latent],axis=1)\n        \n        labelled_disc_y = self.discriminator(labelled_disc_in,training=False)\n        \n        # Updating metrics\n        \n        # For Predictor\n        re_1=[]\n        for i in range(self.hyperparameters['num_tasks']):\n            re_1.append(tf.reshape(labelled_y[i], (hyperparameters['batch_size'], -1)))\n\n        re_2 = []\n        for i in range(self.hyperparameters['num_tasks']):\n            re_2.append(tf.reshape(labelled_prediction_y[i], (hyperparameters['batch_size'], -1)))\n            \n        w = []\n        for i in range(self.hyperparameters['num_tasks']):\n            wts = np.ones((re_1[i].shape))\n            wts=tf.convert_to_tensor(wts)\n            predictor_loss = weighted_cross_entropy(re_1[i], re_2[i], sample_weights=wts)\n            w.append(predictor_loss)\n            \n        w = tf.convert_to_tensor(w)\n        w = tf.math.reduce_mean(w, axis=1) +  tf.cast(dice_coef_loss(re_1, re_2, self.hyperparameters['num_tasks']), tf.float32)\n        \n        self.trackers['loss_tracker_predictor'].update_state(w)\n        self.trackers['acc_metric_predictor'].update_state(re_1, re_2)\n        \n        for task in range(self.hyperparameters['num_tasks']):\n            acc=tf.keras.metrics.BinaryAccuracy()\n            accuracy = acc(re_1[task], re_2[task])\n            self.trackers['individual_acc_predictor'][task].update_state(accuracy)\n            self.trackers['individual_IOU_predictor'][task].update_state(re_1[task], tf.cast(re_2[task]>=0.5, tf.int64))\n        \n        self.trackers['loss_tracker_generator'].update_state(labelled_x, labelled_vae_y)\n        \n        # For Discriminator\n        labelled_disc_true = np.ones((self.hyperparameters['batch_size'],1))\n        self.trackers['loss_tracker_disc'].update_state(labelled_disc_true,labelled_disc_y)\n        self.trackers['acc_tracker_disc'].update_state(labelled_disc_true,labelled_disc_y)\n            \n            \n        ret_dic = {\"loss_predictor_total\": self.trackers['loss_tracker_predictor'].result(), # loss_tracker_predictor.result(), \n                   \"acc_predictor\":self.trackers['acc_metric_predictor'].result(), # acc_metric_predictor.result(), \n                   \"loss_VAE\":  self.trackers['loss_tracker_generator'].result(), # loss_tracker_generator.result(),\n                   \"loss_disc\": self.trackers['loss_tracker_disc'].result(), # loss_tracker_disc.result(),\n                   \"acc_disc\": self.trackers['acc_tracker_disc'].result(), # acc_tracker_disc.result()\n                  }\n        \n        for i in range(hyperparameters['num_tasks']):\n            ret_dic[\"acc_predictor_\"+str(i)] = self.trackers['individual_acc_predictor'][i].result() # individual_acc_metric_predictor[i].result()\n            ret_dic[\"IOU_predictor_\"+str(i)] = self.trackers['individual_IOU_predictor'][i].result() # individual_acc_metric_predictor[i].result()\n        \n        return ret_dic    \n    \n    def predict_step(self, real_images):\n        unlabelled_x, unlabelled_y = real_images\n        \n        # Predictor step\n        unlabelled_prediction_y, unlabelled_predictor_latent = self.predictor(unlabelled_x, training=False)\n        \n        # Generator step\n        unlabelled_vae_y, unlabelled_vae_latent = self.generator(unlabelled_x, training=False)\n        \n        # Discriminator step\n#         unlabelled_predictor_latent = math_ops.mean(ops.convert_to_tensor(unlabelled_predictor_latent), axis=0)\n        unlabelled_disc_in = unlabelled_vae_latent #tf.concat([unlabelled_vae_latent,unlabelled_predictor_latent],axis=1)\n        \n        unlabelled_disc_y = self.discriminator(unlabelled_disc_in,training=False)\n        \n        return unlabelled_disc_y #unlabelled_prediction_y # unlabelled_disc_y#, unlabelled_y\n\n    @property\n    def metrics(self):\n        # We list our `Metric` objects here so that `reset_states()` can be\n        # called automatically at the start of each epoch\n        # or at the start of `evaluate()`.\n        # If you don't implement this property, you have to call\n        # `reset_states()` yourself at the time of your choosing.\n        return [self.trackers[\"loss_tracker_predictor\"], self.trackers[\"acc_metric_predictor\"], self.trackers[\"loss_tracker_generator\"], self.trackers[\"loss_tracker_disc\"], self.trackers[\"acc_tracker_disc\"]] + self.trackers[\"individual_acc_predictor\"] + self.trackers['individual_IOU_predictor']\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def weighted_cross_entropy(y_true, y_pred, sample_weights):\n    y_true = tf.cast(y_true,y_pred.dtype)\n    q1 = -1*(tf.math.multiply(y_true,tf.math.log(y_pred)) + tf.math.multiply((1.0-y_true),tf.math.log(1.0-y_pred)))\n    sample_weights = tf.cast(sample_weights,q1.dtype)\n    z = tf.math.multiply(q1,sample_weights)\n    \n    return tf.math.reduce_mean(z,axis=1)\n\ndef dice_coef(y_true, y_pred):\n    smooth = 1.0\n    y_true_f = tf.cast(K.flatten(y_true), tf.float64)\n    y_pred_f = tf.cast(K.flatten(y_pred), tf.float64)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef dice_coef_loss(y_true, y_pred, num_tasks):\n    t = []\n    for i in range(num_tasks):\n        t.append(1 - dice_coef(y_true[i], y_pred[i]))\n        \n    return tf.convert_to_tensor(t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def uncertainity(probs, weights):\n    lis = []\n    lis_output = []\n    for i in range(hyperparameters['num_tasks']):\n        attr_output = probs[i]\n        w = weights[:,i]\n        k = -1* np.sum(attr_output*np.log(attr_output),axis=1)\n        lis_output.append(k)\n        lis.append(w*k)\n    \n    variance = np.var(np.array(lis),axis=0)\n    return np.array(lis).sum(axis=0), variance\n\ndef getIndices(output, hyperparameters ,pretrain=False):\n    if pretrain == True:\n        count =  hyperparameters['train_initial_batches']*hyperparameters['batch_size']\n        if ((output<=0.5).sum())>=count:\n            sort = np.argwhere(output<=0.5)[:,0]\n            return sort\n        else:\n            selection = (int((hyperparameters['train_initial_batches']*hyperparameters['batch_size'])/1000)+1)*1000\n            sort = np.argpartition((output)[:,0], selection)\n            return sort[:selection]\n    else:\n        count = hyperparameters['num_uncertain_elements']\n        if ((output<=0.5).sum())>=count:\n            sort = np.argwhere(output<=0.5)[:,0]\n            return sort\n        else:\n            selection = (int(hyperparameters['num_uncertain_elements']/1000)+1)*1000\n            sort = np.argpartition((output)[:,0], selection)\n            return sort[:selection]\n        \ndef divide_data(train, initial = False):\n    num_samples = train.values.shape[0]\n    \n    if initial:\n        idx = random.sample(list(np.arange(num_samples)), ((int(hyperparameters['initial_percent_val']*num_samples)//hyperparameters['batch_size'])*hyperparameters['batch_size']))\n    else:\n        idx = random.sample(list(np.arange(num_samples)), ((int(hyperparameters['initial_percent']*num_samples)//hyperparameters['batch_size'])*hyperparameters['batch_size']))\n\n    return pd.DataFrame(train.values[idx,:], columns=train.columns), idx","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# break_point_ep = {'3': 5e-4,'6': 5e-4,'10': 1e-5}\n# splits = [0.1,0.15,0.2,0.25,0.3] #,0.35,0.4]\n\n# # defining metrics\n\n# trackers = {\n#     \"loss_tracker_predictor\": tf.keras.metrics.SparseCategoricalCrossentropy(name=\"loss_predictor_total\"),\n#     \"acc_metric_predictor\": tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc_predictor\"),\n#     'f1_predictor': tf.keras.metrics.Mean(name='f1_predictor'),\n    \n#     \"individual_f1_predictor\": [tf.keras.metrics.Mean(name=\"f1_predictor_\"+str(i)) for i in range(hyperparameters['num_tasks'])],\n                                                 \n#     \"loss_tracker_generator\": tf.keras.metrics.MeanSquaredError(name='loss_VAE'),\n#     \"loss_tracker_disc\":  tf.keras.metrics.BinaryCrossentropy(name='loss_disc'),\n#     \"acc_tracker_disc\": tf.keras.metrics.BinaryAccuracy(\"acc_disc\")\n# }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"break_point_ep = {'3': 1e-5,'6': 1e-5,'10': 1e-5}\nsplits = [0.1, 0.15, 0.2, 0.25, 0.3] # 0.35, 0.4]\n\n# defining metrics\ntrackers = {\n    \"loss_tracker_predictor\": tf.keras.metrics.Mean(name=\"loss_predictor_total\"),# tf.keras.metrics.SparseCategoricalCrossentropy(name=\"loss_predictor_total\"),\n    \"acc_metric_predictor\": tf.keras.metrics.BinaryAccuracy (name=\"acc_predictor\"),\n    \n    #'f1_predictor': tf.keras.metrics.Mean(name='f1_predictor'),\n    #'IOU_predictor': tf.keras.metrics.MeanIoU(name='IOU_predictor', num_classes=hyperparameters['num_tasks']),\n\n    \"individual_acc_predictor\": [tf.keras.metrics.Mean(name=\"acc_predictor_\"+str(i)) for i in range(hyperparameters['num_tasks'])],\n    \"individual_IOU_predictor\": [tf.keras.metrics.MeanIoU(name='IOU_predictor'+str(i), num_classes=2) for i in range(hyperparameters['num_tasks'])],\n    \n    #\"individual_f1_predictor\": [tf.keras.metrics.Mean(name=\"f1_predictor_\"+str(i)) for i in range(hyperparameters['num_tasks'])],\n    #\"individual_f1_predictor\": [tf.keras.metrics.Mean(name=\"f1_predictor_\"+str(i)) for i in range(hyperparameters['num_tasks'])],\n    \"loss_tracker_generator\": tf.keras.metrics.MeanSquaredError(name='loss_VAE'),\n    \"loss_tracker_disc\":  tf.keras.metrics.BinaryCrossentropy(name='loss_disc'),\n    \"acc_tracker_disc\": tf.keras.metrics.BinaryAccuracy(\"acc_disc\")\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CalculatingPredictions(tf.keras.callbacks.Callback):\n    def __init__(self, filename, preds, test_gen, lr, is_validation=False):\n        \n        self.filename = filename\n        self.preds = preds\n        self.test_gen = test_gen\n        self.lr = lr\n        self.is_validation=is_validation\n\n    def on_epoch_end(self, epoch, logs=None):\n        \n#         predict=self.model.evaluate(self.test_gen)\n#         print(predict)\n#         self.preds.append(predict)\n#         k = np.array(self.preds)\n#         if (self.is_validation==True):\n#             np.save(\"./saved_history/\" + self.filename + \"_validation\"+ str(epoch)+ \".npy\", k)\n#         else:\n#             np.save(\"./saved_history/\"+ self.filename + '_' +str(epoch)+ \".npy\", k)\n        \n#         date = datetime.datetime.now().strftime(\"%d - %b - %y - %H:%M:%S\")\n        \n        if (self.is_validation==False and epoch%2==0):\n            self.model.predictor.save_weights(\"./saved_history/models/pred_model_\" + self.filename + \"_epoch\"+str(epoch)+'.h5')\n            self.model.discriminator.save_weights(\"./saved_history/models/disc_model_\" + self.filename +\"_epoch\"+str(epoch)+'.h5')\n            self.model.generator.save_weights(\"./saved_history/models/vae_model_\" + self.filename + \"_epoch\"+str(epoch)+'.h5')\n        elif (self.is_validation==True):\n            self.model.predictor.save_weights(\"./saved_history/models/val_pred_model_\" + self.filename + \"_epoch\"+str(epoch)+'.h5')\n            self.model.discriminator.save_weights(\"./saved_history/models/val_disc_model_\" + self.filename +\"_epoch\"+str(epoch)+'.h5')\n            self.model.generator.save_weights(\"./saved_history/models/val_vae_model_\" + self.filename + \"_epoch\"+str(epoch)+'.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir /kaggle/working/predictions\n!mkdir /kaggle/working/saved_history/\n!mkdir /kaggle/working/saved_history/models\n!mkdir logs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def startTraining(filename, last_iteration, trackers, splits, break_point_ep,  validation_first = False, load_pred_model = False, load_vae = False, load_disc = False, further_training=False):\n    tf.config.run_functions_eagerly(True)\n    \n    preds=[]\n    validation_train_history=[] # new\n    logdir = \"./logs/\" + filename\n    filepath = \"./saved_history/model/\"+filename\n    \n    checkpoint = ModelCheckpoint(filepath, verbose=1, save_best_only=False, mode='max', period = 1)\n    csv_logger = CSVLogger('./saved_history/training_results_'+filename+'.csv', separator = ',', append=True)\n    pre_train_logger = CSVLogger('./saved_history/pre_training_results_'+filename+'.csv', separator = ',', append=True)\n    tensorboard_callback = TensorBoard(log_dir = logdir)\n    pre_tensorboard_callback = TensorBoard(log_dir =\" ./logs/pre_\"+filename)\n        \n    # predictor\n    pred_model = vgg_segnet(n_classes = hyperparameters['num_tasks'], input_height=hyperparameters['height'], input_width=hyperparameters['width'], encoder_level=2, channels=hyperparameters['channels'])\n    pred_model.compile(optimizer = keras.optimizers.SGD(learning_rate=hyperparameters['lr'],\n                                                    clipnorm=1.0 ))\n    \n    if load_pred_model:\n        print(\"Predictor weights loading ...\")\n        pred_model.load_weights(\"../input/celebamask-vaal-345/saved_history/models/pred_model_\" + filename + \"_iteration_\"  + str(last_iteration) + \".h5\", by_name=True)\n        print('loaded')\n        \n    # defining my discriminator\n    disc_in, disc_out = discriminator()\n    disc = Model(inputs = disc_in, outputs = disc_out)\n    disc.compile(optimizer = keras.optimizers.SGD(learning_rate=hyperparameters['lr'],\n                                                  clipnorm=1.0 ))\n\n    if load_disc:\n        print(\"Discriminator weights loading ...\")\n        disc.load_weights(\"../input/celebamask-vaal-345/saved_history/models/disc_model_\" + filename + \"_iteration_\"  + str(last_iteration) + \".h5\", by_name=True)\n        print('loaded')\n\n    # defining my generator\n    X, z, mu = variationalAutoEncoder()\n    vae = Model(inputs = X, outputs = [z,mu])\n    vae.compile(optimizer = keras.optimizers.RMSprop(learning_rate=hyperparameters['lr'],\n                                                     clipnorm=1.0 ))\n    if load_vae:\n        print(\"VAE weights loading ...\")\n        vae.load_weights(\"../input/celebamask-vaal-345/saved_history/models/vae_model_\" + filename + \"_iteration_\"  + str(last_iteration) + \".h5\", by_name=True)\n        print('loaded')\n        \n    # Instantiate AL model\n    AL_model = ActiveLearning(discriminator=disc, generator=vae, predictor=pred_model, hyperparameters=hyperparameters, trackers = trackers)\n    AL_model.compile(\n        d_optimizer=keras.optimizers.SGD(learning_rate=hyperparameters['lr'],clipnorm=1.0 ),\n        g_optimizer= keras.optimizers.RMSprop(learning_rate=hyperparameters['lr'],clipnorm=1.0),\n        p_optimizer=keras.optimizers.SGD(learning_rate=hyperparameters['lr'],clipnorm=1.0 ))\n    \n    print('model loaded')\n    \n    attr = pd.read_csv('/kaggle/input/celebamaskhq/CelebAMask-HQ/CelebAMask-HQ-attribute-anno.txt', skiprows=1, sep=\" \")\n    celeba_to_mask = pd.read_csv('/kaggle/input/celebamaskhq/CelebAMask-HQ/CelebA-HQ-to-CelebA-mapping.txt', header=0, delim_whitespace=True)\n    eval_partition = pd.read_csv('/kaggle/input/celeba-dataset/list_eval_partition.csv')\n\n    (train, val, test) = preprocess(hyperparameters, eval_partition, celeba_to_mask)\n    \n    train_gen_full = DataGenerator(partition['train'], \n                                       labels, hyperparameters['classes'],\n                                       dim = (hyperparameters['height'],hyperparameters['width']),\n                                       batch_size= hyperparameters['batch_size'],\n                                       n_channels = hyperparameters['channels'],\n                                       shuffle = True, \n                                       is_validation=True)\n\n    val_gen = DataGenerator(partition['val'], \n                                       labels, hyperparameters['classes'],\n                                       dim = (hyperparameters['height'],hyperparameters['width']),\n                                       batch_size= hyperparameters['batch_size'],\n                                       n_channels =hyperparameters['channels'],\n                                       shuffle = False, \n                                       is_validation=True)\n\n    test_gen = DataGenerator(partition['test'], \n                                       labels, hyperparameters['classes'],\n                                       dim = (hyperparameters['height'],hyperparameters['width']),\n                                       batch_size= hyperparameters['batch_size'],\n                                       n_channels =hyperparameters['channels'],\n                                       shuffle = False, \n                                       is_validation=True)\n    \n    if validation_first == True:\n        # logger = CSVLogger('./saved_history/pretraining_results_Random_Sampling_model_CelebAMask.csv', separator = ',', append=True)\n        # pre_tensorboard_callback = TensorBoard(log_dir =\" ./logs/pre_\"+filename)\n        \n        labelled_pretrain, idx_prelabelled = divide_data(val, initial=True)\n        idx_preunlabelled = list(np.setdiff1d(list(range(val.shape[0])), idx_prelabelled))\n        unlabelled_pretrain = pd.DataFrame(val.values[idx_preunlabelled,:], columns=val.columns)\n        \n        pretrain_gen = MultipleGenerator(labelled_pretrain.values, \n                                              unlabelled_pretrain.values, \n                                              labels, hyperparameters['classes'],\n                                              batch_size= hyperparameters['batch_size'],\n                                              dim = (hyperparameters['height'],hyperparameters['width']),\n                                              n_channels = hyperparameters['channels'],\n                                              shuffle=True)\n        \n        labelled_pretrain_gen = DataGenerator(unlabelled_pretrain.values, \n                                       labels, hyperparameters['classes'],\n                                       dim = (hyperparameters['height'],hyperparameters['width']),\n                                       batch_size= hyperparameters['batch_size'],\n                                       n_channels = hyperparameters['channels'],\n                                       shuffle = False, \n                                       is_validation=True)\n        \n        val_history = AL_model.fit(pretrain_gen, epochs = hyperparameters['pretraining_epochs'], steps_per_epoch = int((val.shape[0]*hyperparameters['initial_percent_val'])//hyperparameters['batch_size']), callbacks = [CalculatingPredictions(filename, preds, test_gen, 0.01, True) , pre_tensorboard_callback, logger], verbose=1)\n        validation_train_history.append(val_history.history)\n        with open(\"./saved_history/pretraining_history_list_\"+filename+'.json', 'w') as f:\n            json.dump(validation_train_history, f, indent=2)\n            \n        labelled_train, idx_labelled = divide_data(train)\n        idx_unlabelled = list(np.setdiff1d(list(range(train.shape[0])), idx_labelled))\n        unlabelled_train = pd.DataFrame(train.values[idx_unlabelled,:], columns=train.columns)     \n        \n        train_gen = MultipleGenerator(labelled_train.values, \n                                              unlabelled_train.values, \n                                              labels, hyperparameters['classes'],\n                                              batch_size= hyperparameters['batch_size'],\n                                              dim = (hyperparameters['height'],hyperparameters['width']),\n                                              n_channels = hyperparameters['channels'],\n                                              shuffle=True) \n\n        unlabelled_gen = DataGenerator(unlabelled_train.values, \n                                           labels, hyperparameters['classes'],\n                                           dim = (hyperparameters['height'],hyperparameters['width']),\n                                           batch_size= hyperparameters['batch_size'],\n                                           n_channels = hyperparameters['channels'],\n                                           shuffle = False, \n                                           is_validation=True)\n        \n        labelled_gen = DataGenerator(labelled_train.values, \n                                           labels, hyperparameters['classes'],\n                                           dim = (hyperparameters['height'],hyperparameters['width']),\n                                           batch_size= hyperparameters['batch_size'],\n                                           n_channels = hyperparameters['channels'],\n                                           shuffle = False,\n                                           is_validation=True) \n        \n        \n    elif further_training==True:\n    \n        idx_labelled = np.load(\"./saved_history/idx_labelled_4.npy\")\n        labelled_train = train.iloc[idx_labelled, :]\n        idx_unlabelled = list(np.setdiff1d(list(range(train.shape[0])), idx_labelled))\n        unlabelled_train = pd.DataFrame(train.values[idx_unlabelled,:], columns=train.columns)\n\n        train_gen = MultipleGenerator(labelled_train.values, \n                                              unlabelled_train.values, \n                                              labels,hyperparameters['classes'],\n                                              batch_size= hyperparameters['batch_size'],\n                                              dim = (hyperparameters['height'],hyperparameters['width']),\n                                              n_channels = hyperparameters['channels'],\n                                              shuffle=True) \n\n        unlabelled_gen = DataGenerator(unlabelled_train.values, \n                                           labels, hyperparameters['classes'],\n                                           dim = (hyperparameters['height'],hyperparameters['width']),\n                                           batch_size= hyperparameters['batch_size'],\n                                           n_channels = hyperparameters['channels'],\n                                           shuffle = False, is_validation=True)\n        \n        labelled_gen = DataGenerator(labelled_train.values, \n                                           labels, hyperparameters['classes'],\n                                           dim = (hyperparameters['height'],hyperparameters['width']),\n                                           batch_size= hyperparameters['batch_size'],\n                                           n_channels = hyperparameters['channels'],\n                                           shuffle = False, is_validation=True) \n    else:\n        if last_iteration==-1:\n            labelled_train, idx_labelled = divide_data(train)\n            idx_unlabelled = list(np.setdiff1d(list(range(train.shape[0])), idx_labelled))\n            unlabelled_train = pd.DataFrame(train.values[idx_unlabelled,:], columns=train.columns)     \n        else:\n            idx_labelled = np.load(\"../input/celebamask-vaal-345/saved_history/idx_labelled_\" + filename + str(last_iteration)+ \".npy\")\n            print('loaded')\n            idx_labelled=list(idx_labelled)\n            labelled_train = train.iloc[idx_labelled, :]\n            idx_unlabelled = list(np.setdiff1d(list(range(train.shape[0])), idx_labelled))\n            unlabelled_train = pd.DataFrame(train.values[idx_unlabelled,:], columns=train.columns)\n        \n            print(\"checking for uncertainities\")\n            \n            train_gen = MultipleGenerator(labelled_train.values, \n                                              unlabelled_train.values, \n                                              labels, hyperparameters['classes'],\n                                              batch_size= hyperparameters['batch_size'],\n                                              dim = (hyperparameters['height'],hyperparameters['width']),\n                                              n_channels = hyperparameters['channels'],\n                                              shuffle=True) \n\n            unlabelled_gen = DataGenerator(unlabelled_train.values, \n                                               labels, hyperparameters['classes'],\n                                               dim = (hyperparameters['height'],hyperparameters['width']),\n                                               batch_size= hyperparameters['batch_size'],\n                                               n_channels = hyperparameters['channels'],\n                                               shuffle = False, is_validation=True)\n\n            labelled_gen = DataGenerator(labelled_train.values, \n                                               labels, hyperparameters['classes'],\n                                               dim = (hyperparameters['height'],hyperparameters['width']),\n                                               batch_size= hyperparameters['batch_size'],\n                                               n_channels = hyperparameters['channels'],\n                                               shuffle = False, is_validation=True) \n\n            # Get uncertainities\n            disc_output = AL_model.predict(unlabelled_gen, verbose=1)\n\n            unlabelled_indices = getIndices(disc_output, hyperparameters)\n            unlabelled_indices=np.array(unlabelled_indices)\n            img_indice = unlabelled_indices[:hyperparameters['num_uncertain_elements']]\n            print('Number of uncertain indices: ', len(img_indice))\n\n            k = np.array(idx_unlabelled)[img_indice]\n            # k = random.sample(idx_unlabelled, hyperparameters['num_uncertain_elements'])\n            idx_labelled = idx_labelled+list(k)\n\n            labelled_train = pd.DataFrame(train.values[idx_labelled,:], columns=train.columns)\n            idx_unlabelled = list(np.setdiff1d(idx_unlabelled, k))\n            unlabelled_train = pd.DataFrame(train.values[idx_unlabelled,:], columns=train.columns)    \n      \n        train_gen = MultipleGenerator(labelled_train.values, \n                                              unlabelled_train.values, \n                                              labels, hyperparameters['classes'],\n                                              batch_size= hyperparameters['batch_size'],\n                                              dim = (hyperparameters['height'],hyperparameters['width']),\n                                              n_channels = hyperparameters['channels'],\n                                              shuffle=True) \n\n        unlabelled_gen = DataGenerator(unlabelled_train.values, \n                                           labels, hyperparameters['classes'],\n                                           dim = (hyperparameters['height'],hyperparameters['width']),\n                                           batch_size= hyperparameters['batch_size'],\n                                           n_channels = hyperparameters['channels'],\n                                           shuffle = False, is_validation=True)\n        \n        labelled_gen = DataGenerator(labelled_train.values, \n                                           labels, hyperparameters['classes'],\n                                           dim = (hyperparameters['height'],hyperparameters['width']),\n                                           batch_size= hyperparameters['batch_size'],\n                                           n_channels = hyperparameters['channels'],\n                                           shuffle = False, is_validation=True) \n    \n    history_list=[]\n    if further_training==True:\n        num_batches = 10 #idx_labelled.shape[0]//hyperparameters['batch_size']\n        tensorboard_callback = TensorBoard(log_dir = 'AL_model_from_scratch_non_cs_09 - Jan - 21 - 12:50:36')\n\n        iteration =5\n        epoch_num = 13\n        \n        history = AL_model.fit(train_gen,initial_epoch = epoch_num, epochs=epoch_num+7, steps_per_epoch = num_batches, validation_data=val_gen,callbacks = [CalculatingPredictions(preds, test_gen, 0.01), csv_logger], verbose = 1)\n        history_list.append(history.history)\n        pred_model.save_weights(\"./saved_history/models/pred_model_from_scratch_vanilla_\"+str(iteration)+'.h5')\n        disc.save_weights(\"./saved_history/models/disc_model_from_scratch_vanilla_\"+str(iteration)+'.h5')\n        vae.save_weights(\"./saved_history/models/vae_model_from_scratch_vanilla_\"+str(iteration)+'.h5')\n        with open(\"./saved_history/history_list_only_\"+str(iteration)+\".json\", 'w') as f:\n            json.dump(history_list, f, indent=2)\n\n        with open(\"./saved_history/preds_only_\"+str(iteration)+\".json\", 'w') as f:\n            json.dump(preds, f, indent=2)\n                                    \n    else:\n        test_predictions=[]\n        indices_list = []\n        epoch_num = 0        \n        num_batches = (train.shape[0]*splits[hyperparameters['split_index']])//hyperparameters['batch_size']\n        \n        for iteration in range(len(splits)): \n            if iteration in list(range(last_iteration+1)):\n                epoch_num+=hyperparameters['increment_train_epoch']+iteration\n                continue\n                \n            print(iteration, splits[iteration], len(train_gen))\n            \n            if iteration==0:\n                # Initial training ---- change\n                history = AL_model.fit(train_gen, epochs=hyperparameters['initial_train_epoch'], steps_per_epoch = num_batches, validation_data=val_gen, callbacks = [CalculatingPredictions(filename, preds, test_gen, 0.01), csv_logger, tensorboard_callback], verbose = 1)\n                history_list.append(history.history)\n                epoch_num+=hyperparameters['initial_train_epoch']\n            else:\n                # predictor\n                pred_model = vgg_segnet(n_classes = hyperparameters['num_tasks'], input_height=hyperparameters['height'], input_width=hyperparameters['width'], encoder_level=2, channels=hyperparameters['channels'])\n                pred_model.compile(optimizer = keras.optimizers.SGD(learning_rate=hyperparameters['lr'],\n                                                                clipnorm=1.0 ))\n\n                # pred_model.load_weights(\"./saved_history/models/pred_model_from_scratch_vanilla_4.h5\", by_name=True)\n\n                # defining my discriminator\n                disc_in, disc_out = discriminator()\n                disc = Model(inputs = disc_in, outputs = disc_out)\n                disc.compile(optimizer = keras.optimizers.SGD(learning_rate=hyperparameters['lr'],\n                                                              clipnorm=1.0 ))\n\n                # defining my generator\n                X, z, mu = variationalAutoEncoder()\n                vae = Model(inputs = X, outputs = [z,mu])\n                vae.compile(optimizer = keras.optimizers.RMSprop(learning_rate=hyperparameters['lr'],\n                                                                 clipnorm=1.0 ))\n                \n                if validation_first==True:\n                    pred_model.load_weights(\"./saved_history/models/val_pred_model_\" + filename + \"_epoch2\"+'.h5', by_name=True)\n                    vae.load_weights(\"./saved_history/models/val_vae_model_\" + filename + \"_epoch2\"+'.h5', by_name=True)\n                    disc.load_weights(\"./saved_history/models/val_disc_model_\" + filename + \"_epoch2\"+'.h5', by_name=True)\n                \n                # Instantiate AL model\n                AL_model = ActiveLearning(discriminator=disc, generator=vae, predictor=pred_model, hyperparameters=hyperparameters, trackers = trackers)\n                AL_model.compile(\n                    d_optimizer=keras.optimizers.SGD(learning_rate=hyperparameters['lr'],clipnorm=1.0 ),\n                    g_optimizer= keras.optimizers.RMSprop(learning_rate=hyperparameters['lr'],clipnorm=1.0),\n                    p_optimizer=keras.optimizers.SGD(learning_rate=hyperparameters['lr'],clipnorm=1.0 ))\n\n                print('model loaded')\n                \n                # Increment training --- change\n                history = AL_model.fit(train_gen, initial_epoch = epoch_num, epochs=epoch_num+hyperparameters['increment_train_epoch'] + iteration, steps_per_epoch = num_batches, validation_data=val_gen,callbacks = [CalculatingPredictions(filename, preds, test_gen, 0.01), csv_logger, tensorboard_callback], verbose = 1)\n                history_list.append(history.history)\n                epoch_num+=hyperparameters['increment_train_epoch']+iteration\n                \n            pred_model.save_weights(\"./saved_history/models/pred_model_\" + filename +\"_iteration_\"+str(iteration)+'.h5')\n            disc.save_weights(\"./saved_history/models/disc_model_\" + filename + \"_iteration_\"+str(iteration)+'.h5')\n            vae.save_weights(\"./saved_history/models/vae_model_\"+ filename + \"_iteration_\"+str(iteration)+'.h5')        \n\n            indices_list.append(idx_labelled)\n            inc = int(train.shape[0]*0.05 /  hyperparameters['batch_size'])\n            num_batches+= inc\n            print('Number of batches added:' , inc)       \n\n            with open(\"./saved_history/history_list_\"+filename+str(iteration)+\".json\", 'w') as f:\n                json.dump(history_list, f, indent=2)\n\n            with open(\"./saved_history/preds_\"+filename+str(iteration)+\".json\", 'w') as f:\n                json.dump(preds, f, indent=2)\n\n            np.save(\"./saved_history/idx_labelled_\"+filename+str(iteration)+\".npy\",np.array(idx_labelled))       \n            \n            if (iteration!=(len(splits)-1)): # last iteration\n                \n                print(\"checking for uncertainities\")\n                \n                # Get uncertainities\n                disc_output = AL_model.predict(unlabelled_gen, verbose=1)\n                \n                unlabelled_indices = getIndices(disc_output, hyperparameters)\n                unlabelled_indices=np.array(unlabelled_indices)\n                img_indice = unlabelled_indices[:hyperparameters['num_uncertain_elements']]\n                print('Number of uncertain indices: ', len(img_indice))\n                \n                k = np.array(idx_unlabelled)[img_indice]\n                # k = random.sample(idx_unlabelled, hyperparameters['num_uncertain_elements'])\n                \n                idx_labelled = idx_labelled+list(k)\n                \n                labelled_train = pd.DataFrame(train.values[idx_labelled,:], columns=train.columns)\n                idx_unlabelled = list(np.setdiff1d(idx_unlabelled, k))\n                unlabelled_train = pd.DataFrame(train.values[idx_unlabelled,:], columns=train.columns)            \n                \n                train_gen = MultipleGenerator(labelled_train.values, \n                                              unlabelled_train.values, \n                                              labels, hyperparameters['classes'],\n                                              batch_size= hyperparameters['batch_size'],\n                                              dim = (hyperparameters['height'],hyperparameters['width']),\n                                              n_channels = hyperparameters['channels'],\n                                              shuffle = True)\n\n                unlabelled_gen = DataGenerator(unlabelled_train.values, \n                                       labels, hyperparameters['classes'],\n                                       dim = (hyperparameters['height'],hyperparameters['width']),\n                                       batch_size= hyperparameters['batch_size'],\n                                       n_channels = hyperparameters['channels'],\n                                       shuffle = False, is_validation=True)\n                \n                labelled_gen = DataGenerator(labelled_train.values, \n                               labels, hyperparameters['classes'],\n                               dim = (hyperparameters['height'],hyperparameters['width']),\n                               batch_size= hyperparameters['batch_size'],\n                               n_channels = hyperparameters['channels'],\n                               shuffle = False, is_validation=True)\n                                               \n    return history_list, pred_model, vae, disc, AL_model, indices_list, preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"attempt = '1'\ncls = 'classes1'\nfilename = \"VAAL_CelebAMask_\" + cls + '_' + attempt\nlast_iteration = 3\n\nhistory_list, pred_model, vae, disc, Al_model, indices_list, preds = startTraining(filename, last_iteration, trackers, splits, break_point_ep, False, False, False, False, False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}